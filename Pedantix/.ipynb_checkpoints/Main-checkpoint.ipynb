{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "119eac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ed48d",
   "metadata": {},
   "source": [
    "##### Prepare the mostly used words from the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "677e65b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nf = open(\\'most french word used.txt\\', \\'r\\', encoding=\\'utf-8\\')\\nlines = f.readlines()\\n\\nwords = []\\n\\ncount = 0\\nfor line in lines:\\n    count +=1\\n    if(count%2 == 0):\\n        continue\\n        \\n    word = line.split(\"]]\")[0][4:]\\n    words.append(word)\\n    \\nwith open(\\'Wikipedia words mostly used.txt\\', \\'w\\') as f:\\n    for word in words:\\n        f.write(word)\\n        f.write(\\'\\n\\')\\n'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "f = open('most french word used.txt', 'r', encoding='utf-8')\n",
    "lines = f.readlines()\n",
    "\n",
    "words = []\n",
    "\n",
    "count = 0\n",
    "for line in lines:\n",
    "    count +=1\n",
    "    if(count%2 == 0):\n",
    "        continue\n",
    "        \n",
    "    word = line.split(\"]]\")[0][4:]\n",
    "    words.append(word)\n",
    "    \n",
    "with open('Wikipedia words mostly used.txt', 'w') as f:\n",
    "    for word in words:\n",
    "        f.write(word)\n",
    "        f.write('\\n')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4707cc4",
   "metadata": {},
   "source": [
    "# Show words on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b8f4d0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "file = 'Wikipedia words mostly used.txt'\n",
    "with open(file) as word_file:\n",
    "    words = word_file.read().split()\n",
    "    \n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "29a6af66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antoine\\AppData\\Local\\Temp/ipykernel_4072/3195080691.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('./chromedriver')\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('./chromedriver')\n",
    "driver.get(\"https://cemantix.certitudes.org/pedantix\")\n",
    "\n",
    "#close for pop up\n",
    "close_box = driver.find_element(\"id\", \"dialog-close\")\n",
    "driver.execute_script(\"arguments[0].click();\", close_box); #close the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "efa2b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "send_box = driver.find_element(\"id\", \"pedantix-guess-btn\")\n",
    "\n",
    "for word in words:\n",
    "    text_box = driver.find_element(\"id\", \"pedantix-guess\")\n",
    "    text_box.send_keys(word)\n",
    "    \n",
    "    driver.execute_script(\"arguments[0].click();\", send_box);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b257e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a8e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3efea69",
   "metadata": {},
   "source": [
    "## Send request and guess the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "53427573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5070\n"
     ]
    }
   ],
   "source": [
    "file = 'words.txt'\n",
    "with open(file) as word_file:\n",
    "    allWords = word_file.read().split()\n",
    "    \n",
    "print(len(allWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d9744fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = allWords[0:20] + [ \"Kazakhstan\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f37ba887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word is Kazakhstan\n",
      "0.7414360046386719 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for word in words:\n",
    "    r = requests.post('https://cemantix.certitudes.org/pedantix/score', json = {\"word\": word,\"answer\":[word]})\n",
    "    score = r.json()[ 'score' ]\n",
    "    if '0' in score:\n",
    "        print(\"The word is\", word )\n",
    "        \n",
    "print(\"%s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a1178bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mwxml\n",
      "  Downloading mwxml-0.3.3-py2.py3-none-any.whl (32 kB)\n",
      "Collecting mwtypes>=0.3.0\n",
      "  Downloading mwtypes-0.3.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: jsonschema>=2.5.1 in c:\\users\\antoine\\anaconda3\\lib\\site-packages (from mwxml) (3.2.0)\n",
      "Collecting mwcli>=0.0.2\n",
      "  Downloading mwcli-0.0.3-py2.py3-none-any.whl (8.4 kB)\n",
      "Collecting para>=0.0.1\n",
      "  Downloading para-0.0.8-py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\antoine\\anaconda3\\lib\\site-packages (from jsonschema>=2.5.1->mwxml) (21.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\antoine\\anaconda3\\lib\\site-packages (from jsonschema>=2.5.1->mwxml) (58.0.4)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\antoine\\anaconda3\\lib\\site-packages (from jsonschema>=2.5.1->mwxml) (0.18.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\antoine\\anaconda3\\lib\\site-packages (from jsonschema>=2.5.1->mwxml) (1.16.0)\n",
      "Requirement already satisfied: docopt in c:\\users\\antoine\\anaconda3\\lib\\site-packages (from mwcli>=0.0.2->mwxml) (0.6.2)\n",
      "Collecting jsonable>=0.3.0\n",
      "  Downloading jsonable-0.3.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: para, jsonable, mwtypes, mwcli, mwxml\n",
      "Successfully installed jsonable-0.3.1 mwcli-0.0.3 mwtypes-0.3.2 mwxml-0.3.3 para-0.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install mwxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f5f46ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16fd4add",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikipÃ©dia frwiki\n"
     ]
    }
   ],
   "source": [
    "dump = mwxml.Dump.from_file(open(\"frwiki-20230301-pages-articles-multistream1.xml-p1p306134\",'r', encoding='utf-8'))\n",
    "print(dump.site_info.name, dump.site_info.dbname)\n",
    "count = 0\n",
    "for page in dump:\n",
    "    for revision in page:\n",
    "        continue\n",
    "    count +=1\n",
    "    #if(count > 10): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5c290aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165995\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7e741",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> dump = mwxml.Dump.from_file(open(\"frwiki-20230301-pages-articles-multistream1.xml-p1p306134\"\"))\n",
    ">>> print(dump.site_info.name, dump.site_info.dbname)\n",
    "Wikipedia enwiki\n",
    ">>>\n",
    ">>> for page in dump:\n",
    "...     for revision in page:\n",
    "...        print(revision.id)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b44db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d93e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "61a08945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e7740ba6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/enwiki-20190620-pages-articles-multistream.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4072/3920215504.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/enwiki-20190620-pages-articles-multistream.xml'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mtname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrip_tag_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\xml\\etree\\ElementTree.py\u001b[0m in \u001b[0;36miterparse\u001b[1;34m(source, events, parser)\u001b[0m\n\u001b[0;32m   1273\u001b[0m     \u001b[0mclose_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1275\u001b[1;33m         \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1276\u001b[0m         \u001b[0mclose_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/enwiki-20190620-pages-articles-multistream.xml'"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "def strip_tag_name(t):\n",
    "    t = elem.tag\n",
    "    idx = k = t.rfind(\"}\")\n",
    "    if idx != -1:\n",
    "        t = t[idx + 1:]\n",
    "    return t\n",
    "\n",
    "\n",
    "events = (\"start\", \"end\")\n",
    "\n",
    "title = None\n",
    "for event, elem in ET.iterparse('data/enwiki-20190620-pages-articles-multistream.xml', events=events):\n",
    "    tname = strip_tag_name(elem.tag)\n",
    "\n",
    "    if event == 'end':\n",
    "        if tname == 'title':\n",
    "            title = elem.text\n",
    "        elif tname == 'text':\n",
    "            print(title, elem.text)\n",
    "\n",
    "    elem.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0999cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
